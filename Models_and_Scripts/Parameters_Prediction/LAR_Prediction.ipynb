{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "config = config[\"lar_prediction\"]\n",
    "\n",
    "def set_seeds(seed=config[\"training\"][\"random_seed\"]):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_NUM_INTRAOP_THREADS'] = '1'\n",
    "    os.environ['TF_NUM_INTEROP_THREADS'] = '1'\n",
    "\n",
    "set_seeds()\n",
    "\n",
    "data = pd.read_csv(config[\"data\"][\"historical_data_path\"])\n",
    "data['Date'] = pd.to_datetime(data['Date'], format='%Y-%m-%d')\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "timeseries_data = data['LAR'].values.reshape(-1, 1)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "timeseries_data_scaled = scaler.fit_transform(timeseries_data)\n",
    "\n",
    "def prepare_data(series, n_steps):\n",
    "    X, y = [], []\n",
    "    for i in range(len(series) - n_steps):\n",
    "        X.append(series[i:i + n_steps])\n",
    "        y.append(series[i + n_steps])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(config[\"model\"][\"lstm_units_1\"], return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(config[\"model\"][\"dropout_rate_1\"]),\n",
    "        LSTM(config[\"model\"][\"lstm_units_2\"], return_sequences=True),\n",
    "        Dropout(config[\"model\"][\"dropout_rate_2\"]),\n",
    "        LSTM(config[\"model\"][\"lstm_units_3\"]),\n",
    "        Dense(config[\"model\"][\"dense_units\"], activation='relu'),\n",
    "        Dense(1, activation='relu')\n",
    "    ])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=config[\"model\"][\"learning_rate\"]),\n",
    "        loss=config[\"model\"][\"loss_function\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def generate_future_predictions(model, last_sequence, n_steps, n_features, scaler, \n",
    "                              batch_size=config[\"forecast\"][\"batch_size\"], \n",
    "                              end_date=datetime.datetime.strptime(config[\"forecast\"][\"forecast_end_date\"], \"%Y-%m-%d\"), \n",
    "                              retrain=config[\"forecast\"][\"retrain\"]):\n",
    "    predictions_dict = {}  \n",
    "    current_date = data.index[-1]\n",
    "    \n",
    "    current_sequence = last_sequence.reshape(1, n_steps, n_features)\n",
    "    all_data_scaled = timeseries_data_scaled.copy()\n",
    "    \n",
    "    while current_date < end_date:\n",
    "        batch_predictions = []\n",
    "        batch_dates = []\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            current_date += pd.DateOffset(days=1)\n",
    "            if current_date > end_date:\n",
    "                break\n",
    "                \n",
    "            next_pred = model.predict(current_sequence, verbose=0)[0, 0]\n",
    "            \n",
    "            batch_predictions.append(next_pred)\n",
    "            batch_dates.append(current_date)\n",
    "            \n",
    "            current_sequence = np.roll(current_sequence, -1, axis=1)\n",
    "            current_sequence[0, -1, 0] = next_pred\n",
    "        \n",
    "        if not batch_predictions:  \n",
    "            break\n",
    "            \n",
    "        batch_predictions = np.array(batch_predictions).reshape(-1, 1)\n",
    "        batch_predictions_inv = scaler.inverse_transform(batch_predictions)\n",
    "        \n",
    "        for date, pred in zip(batch_dates, batch_predictions_inv.flatten()):\n",
    "            predictions_dict[date] = pred\n",
    "        \n",
    "        if retrain:\n",
    "            all_data_scaled = np.vstack([all_data_scaled, batch_predictions])\n",
    "            \n",
    "            X_new, y_new = prepare_data(all_data_scaled, n_steps)\n",
    "            X_new = X_new.reshape((X_new.shape[0], X_new.shape[1], n_features))\n",
    "            \n",
    "            model.fit(X_new, y_new, epochs=5, batch_size=config[\"model\"][\"batch_size\"], verbose=0)\n",
    "            print(f\"Model retrained - Current date: {current_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "    predictions_series = pd.Series(predictions_dict, name='Predicted_LAR')\n",
    "    predictions_series.index.name = 'Date'\n",
    "    return predictions_series\n",
    "\n",
    "n_steps = config[\"sequence\"][\"seq_length\"]\n",
    "n_features = 1\n",
    "X, y = prepare_data(timeseries_data_scaled, n_steps)\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))\n",
    "\n",
    "print(\"Training model on complete dataset...\")\n",
    "model = build_lstm_model((n_steps, n_features))\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=config[\"training\"][\"patience\"], restore_best_weights=True)\n",
    "history = model.fit(X, y, epochs=config[\"model\"][\"epochs\"], batch_size=config[\"model\"][\"batch_size\"], \n",
    "                    callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "print(f\"\\nGenerating predictions until {config['forecast']['forecast_end_date']}...\")\n",
    "last_sequence = timeseries_data_scaled[-n_steps:]\n",
    "future_predictions = generate_future_predictions(\n",
    "    model=model,\n",
    "    last_sequence=last_sequence,\n",
    "    n_steps=n_steps,\n",
    "    n_features=n_features,\n",
    "    scaler=scaler,\n",
    "    batch_size=config[\"forecast\"][\"batch_size\"],  \n",
    "    end_date=datetime.datetime.strptime(config[\"forecast\"][\"forecast_end_date\"], \"%Y-%m-%d\"),\n",
    "    retrain=config[\"forecast\"][\"retrain\"]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.plot(data.index, data['LAR'], label='Historical LAR', color='blue')\n",
    "plt.plot(future_predictions.index, future_predictions.values, \n",
    "         label='Predicted LAR', color='red', linestyle='--')\n",
    "plt.axvline(x=data.index[-1], color='green', linestyle=':', label='Prediction Start')\n",
    "plt.title('LAR: Historical and Predicted Values until 2026')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('LAR')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "output_df = pd.DataFrame(future_predictions)\n",
    "output_df.reset_index(inplace=True)\n",
    "output_df.to_csv(config[\"data\"][\"prediction_output_path\"], index=False)\n",
    "print(f\"\\nPredictions saved to '{config['data']['prediction_output_path']}'\")\n",
    "\n",
    "print(\"\\nPrediction Summary:\")\n",
    "print(f\"Prediction Start Date: {data.index[-1].strftime('%Y-%m-%d')}\")\n",
    "print(f\"Prediction End Date: {future_predictions.index[-1].strftime('%Y-%m-%d')}\")\n",
    "print(f\"Number of days predicted: {len(future_predictions)}\")\n",
    "print(f\"Initial LAR: {data['LAR'].iloc[-1]:.2f}\")\n",
    "print(f\"Final Predicted LAR: {future_predictions.iloc[-1]:.2f}\")\n",
    "print(f\"Minimum Predicted LAR: {future_predictions.min():.2f}\")\n",
    "print(f\"Maximum Predicted LAR: {future_predictions.max():.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
