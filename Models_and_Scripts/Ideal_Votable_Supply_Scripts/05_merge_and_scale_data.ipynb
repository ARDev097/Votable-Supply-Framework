{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load settings from config.yaml\n",
    "with open(\"config.yaml\", 'r') as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_historical_data_path = config['prepare_historical_data']['data']['merged_historical_data_path']\n",
    "merged_future_data_path = config['prepare_future_data']['data']['merged_future_data_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data = pd.read_csv(merged_historical_data_path, parse_dates=['Date'])\n",
    "future_data = pd.read_csv(merged_future_data_path, parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([hist_data, future_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Parameters Using MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OP_Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min OP Price -', round(data['OP_Price'].min(), 2))\n",
    "print('Max OP Price -', round(data['OP_Price'].max(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax scaling of OP_Price\n",
    "scaler = MinMaxScaler()\n",
    "data['OP_Price_Scaled'] = scaler.fit_transform(data[['OP_Price']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min Scaled OP Price -', round(data['OP_Price_Scaled'].min(), 2))\n",
    "print('Max Scaled OP Price -',round(data['OP_Price_Scaled'].max(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AVPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min AVPI -', round(data['AVPI'].min(), 2))\n",
    "print('Max AVPI -', round(data['AVPI'].max(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax scaling of AVPI\n",
    "scaler = MinMaxScaler()\n",
    "data['AVPI_Scaled'] = scaler.fit_transform(data[['AVPI']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min Scaled AVPI -', round(data['AVPI_Scaled'].min(), 2))\n",
    "print('Max Scaled AVPI -', round(data['AVPI_Scaled'].max(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min PR -', round(data['PR'].min(), 2))\n",
    "print('Max PR -', round(data['PR'].max(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax scaling of PR\n",
    "scaler = MinMaxScaler()\n",
    "data['PR_Scaled'] = scaler.fit_transform(data[['PR']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min Scaled PR -', round(data['PR_Scaled'].min(), 2))\n",
    "print('Max Scaled PR -', round(data['PR_Scaled'].max(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min LAR -', round(data['LAR'].min(), 2))\n",
    "print('Max LAR -', round(data['LAR'].max(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MinMax scaling of LAR\n",
    "scaler = MinMaxScaler()\n",
    "data['LAR_Scaled'] = scaler.fit_transform(data[['LAR']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Min Scaled LAR -', round(data['LAR_Scaled'].min(), 2))\n",
    "print('Max Scaled LAR -', round(data['LAR_Scaled'].max(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_parameters_merged_data_path = config['merge_and_scale_data']['data']['all_parameters_merged_data_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(all_parameters_merged_data_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate correlation and normalize it\n",
    "def calculate_normalized_correlations(data, target_column):\n",
    "    \"\"\"\n",
    "    Calculate normalized absolute correlations of all columns with the target column.\n",
    "    \"\"\"\n",
    "    correlation_matrix = data.corr()\n",
    "    absolute_correlations = correlation_matrix[target_column].abs().drop(target_column)\n",
    "    normalized_correlations = absolute_correlations / absolute_correlations.sum()\n",
    "    normalized_correlations = normalized_correlations.round(2).sort_values(ascending=False)\n",
    "    print(\"Normalized Correlations:\")\n",
    "    print(normalized_correlations)\n",
    "    return normalized_correlations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate weightage ranges based on normalized weights\n",
    "def calculate_weightage_ranges(weights, k=1):\n",
    "    \"\"\"\n",
    "    Calculate weightage ranges for each parameter based on its weight.\n",
    "    \"\"\"\n",
    "    weight_values = np.array(list(weights.values()))\n",
    "    std_dev_weight = np.std(weight_values)\n",
    "\n",
    "    ranges = {\n",
    "        param: (max(weight - k * std_dev_weight, 0), weight + k * std_dev_weight) \n",
    "        for param, weight in weights.items()\n",
    "    }\n",
    "\n",
    "    print(\"\\nWeightage Ranges for Each Parameter:\")\n",
    "    for param, (low, high) in ranges.items():\n",
    "        print(f\"{param}: [{low:.2f}, {high:.2f}]\")\n",
    "\n",
    "    return ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    data = pd.read_csv(all_parameters_merged_data_path)\n",
    "    data = data[['OP_Price_Scaled', 'AVPI_Scaled', 'PR_Scaled', 'LAR_Scaled', 'Votable Supply']]\n",
    "\n",
    "    # Step 1: Calculate and display the correlation matrix\n",
    "    correlation_matrix = data.corr()\n",
    "    print(\"\\nCorrelation Matrix:\")\n",
    "    print(correlation_matrix)\n",
    "\n",
    "    # Step 2: Plot the heatmap of the correlation matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "    plt.title('Correlation Heatmap')\n",
    "    plt.show()\n",
    "\n",
    "    # Step 3: Calculate normalized correlations\n",
    "    target_column = 'Votable Supply'\n",
    "    normalized_correlations = calculate_normalized_correlations(data, target_column)\n",
    "\n",
    "    # Step 4: Use normalized correlations as weights to calculate ranges\n",
    "    weights = normalized_correlations.to_dict()\n",
    "    weightage_ranges = calculate_weightage_ranges(weights)\n",
    "\n",
    "    # Step 5: Plot Normalized Correlations\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    bars = plt.bar(normalized_correlations.index, normalized_correlations.values, color='skyblue')\n",
    "\n",
    "    for bar in bars:\n",
    "        plt.text(\n",
    "            bar.get_x() + bar.get_width() / 2,  \n",
    "            bar.get_height() + 0.01,           \n",
    "            f'{bar.get_height():.2f}',        \n",
    "            ha='center', va='bottom', fontsize=10, color='black' \n",
    "        )\n",
    "\n",
    "    plt.title('Normalized Correlations with Votable Supply')\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Normalized Correlation')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    # Step 6: Plot Weightage Ranges\n",
    "    weightage_low = [low for low, _ in weightage_ranges.values()]\n",
    "    weightage_high = [high for _, high in weightage_ranges.values()]\n",
    "    params = list(weightage_ranges.keys())\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(params, weightage_high, color='lightcoral', label='Range')\n",
    "    plt.barh(params, weightage_low, color='white')\n",
    "    plt.title('Weightage Ranges for Each Parameter')\n",
    "    plt.xlabel('Weight Range')\n",
    "    plt.ylabel('Parameter')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "votable_supply",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
