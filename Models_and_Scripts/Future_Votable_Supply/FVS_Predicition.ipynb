{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas numpy scikit-learn matplotlib tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seeds(seed=42):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    tf.keras.utils.set_random_seed(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_NUM_INTRAOP_THREADS'] = '1'\n",
    "    os.environ['TF_NUM_INTEROP_THREADS'] = '1'\n",
    "\n",
    "def load_and_prepare_data(price_file, cs_file, vs_file, future_cs_file):\n",
    "    price_df = pd.read_csv(price_file)\n",
    "    cs_df = pd.read_csv(cs_file)\n",
    "    vs_df = pd.read_csv(vs_file)\n",
    "    future_cs_df = pd.read_csv(future_cs_file)\n",
    "    \n",
    "    price_df['Date'] = pd.to_datetime(price_df['Date'], format='%m/%d/%Y')\n",
    "    cs_df['Date'] = pd.to_datetime(cs_df['Date'], format='%d/%m/%Y')\n",
    "    vs_df['Date'] = pd.to_datetime(vs_df['Date'], format='%d/%m/%Y')\n",
    "    future_cs_df['Date'] = pd.to_datetime(future_cs_df['Date'], format='%Y-%m-%d')\n",
    "    \n",
    "    price_df.columns = ['Date', 'Price']\n",
    "    merged_df = pd.merge(vs_df, cs_df, on='Date', how='inner')\n",
    "    merged_df = pd.merge(merged_df, price_df, on='Date', how='inner')\n",
    "    \n",
    "    merged_df = merged_df.sort_values('Date')\n",
    "    future_cs_df = future_cs_df.sort_values('Date')\n",
    "    \n",
    "    return merged_df, future_cs_df\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i + seq_length])\n",
    "        y.append(data[i + seq_length, 0])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def build_lstm_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(100, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(25),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "    return model\n",
    "\n",
    "def predict_until_target_date(price_file, cs_file, vs_file, future_cs_file, target_date, batch_size=30, sequence_length=60, seed=42):\n",
    "    set_seeds(seed)\n",
    "    df, future_cs_df = load_and_prepare_data(price_file, cs_file, vs_file, future_cs_file)\n",
    "    feature_columns = ['Votable Supply', 'Circulating Supply', 'Price']\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_data = scaler.fit_transform(df[feature_columns])\n",
    "    target_date = pd.to_datetime(target_date)\n",
    "    current_date = df['Date'].iloc[-1]\n",
    "    all_predictions = []\n",
    "    all_dates = []\n",
    "    \n",
    "    while current_date < target_date:\n",
    "        X, y = create_sequences(scaled_data, sequence_length)\n",
    "        set_seeds(seed)\n",
    "        model = build_lstm_model((sequence_length, X.shape[2]))\n",
    "        model.fit(X, y, epochs=50, batch_size=32, verbose=0)\n",
    "        \n",
    "        current_sequence = scaled_data[-sequence_length:].reshape(1, sequence_length, len(feature_columns))\n",
    "        batch_predictions = []\n",
    "        batch_dates = []\n",
    "        \n",
    "        for _ in range(batch_size):\n",
    "            if current_date >= target_date:\n",
    "                break\n",
    "            current_date += timedelta(days=1)\n",
    "            batch_dates.append(current_date)\n",
    "            future_cs = future_cs_df[future_cs_df['Date'] == current_date]['Circulating Supply'].iloc[0]\n",
    "            next_pred = float(model.predict(current_sequence, verbose=0)[0])\n",
    "            batch_predictions.append(next_pred)\n",
    "            last_step = current_sequence[0, -1:, :].copy()\n",
    "            last_step[0, 0] = next_pred\n",
    "            temp_data = df[feature_columns].iloc[-1:].copy()\n",
    "            temp_data['Circulating Supply'] = future_cs\n",
    "            scaled_future_cs = scaler.transform(temp_data)[0, 1]\n",
    "            last_step[0, 1] = scaled_future_cs\n",
    "            current_sequence = np.concatenate([\n",
    "                current_sequence[:, 1:, :],\n",
    "                last_step.reshape(1, 1, len(feature_columns))\n",
    "            ], axis=1)\n",
    "        \n",
    "        prediction_matrix = np.zeros((len(batch_predictions), len(feature_columns)))\n",
    "        prediction_matrix[:, 0] = batch_predictions\n",
    "        future_cs_values = [future_cs_df[future_cs_df['Date'] == date]['Circulating Supply'].iloc[0] for date in batch_dates]\n",
    "        prediction_matrix[:, 1] = future_cs_values\n",
    "        prediction_matrix[:, 2] = df[feature_columns].iloc[-1]['Price']\n",
    "        unscaled_predictions = scaler.inverse_transform(prediction_matrix)[:, 0]\n",
    "        all_predictions.extend(unscaled_predictions)\n",
    "        all_dates.extend(batch_dates)\n",
    "        new_data = np.zeros((len(batch_predictions), len(feature_columns)))\n",
    "        new_data[:, 0] = unscaled_predictions\n",
    "        new_data[:, 1] = future_cs_values\n",
    "        new_data[:, 2] = df[feature_columns].iloc[-1]['Price']\n",
    "        scaled_new_data = scaler.transform(new_data)\n",
    "        scaled_data = np.vstack([scaled_data, scaled_new_data])\n",
    "    \n",
    "    predictions_df = pd.DataFrame({\n",
    "        'Date': all_dates,\n",
    "        'Predicted_Votable_Supply': all_predictions\n",
    "    })\n",
    "    \n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(df['Date'], df['Votable Supply'], label='Historical Votable Supply')\n",
    "    plt.plot(predictions_df['Date'], predictions_df['Predicted_Votable_Supply'], label='Predicted Votable Supply', linestyle='--')\n",
    "    plt.title('Votable Supply: Historical and Predicted (Until Dec 2026)')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Votable Supply')\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return predictions_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    set_seeds(42)\n",
    "    target_date = '2026-12-31'\n",
    "    predictions = predict_until_target_date(\n",
    "    '../../Dataset/Historical_Data/OP_Price/OP_Price_Historical_Data.csv',\n",
    "    '../../Dataset/Historical_Data/Circulating_Supply/CS_Historical_Data.csv',\n",
    "    '../../Dataset/Historical_Data/Votable_Supply/VS_Historical_Data.csv',\n",
    "    '../../Dataset/Future_Circulating_Supply/FCS_Daywise_Data.csv',\n",
    "        target_date,\n",
    "        seed=42\n",
    "    )\n",
    "    predictions.to_csv('../../Dataset/Future_Votable_Supply/FVS_Daywise_Data.csv', index=False)\n",
    "    print(\"\\nPredictions saved to '../../Dataset/Future_Votable_Supply/FVS_Daywise_Data.csv'\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
